{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage.draw import polygon_perimeter\n",
    "from skimage import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "path_base = Path(r\"PASTE-FULL-PATH-TO-ANALYSIS-FOLDER\")\n",
    "image_size = (1024,1024)\n",
    "dist_max = 90\n",
    "bin_step = 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batch process folder\n",
    "\n",
    "# Different folders\n",
    "path_json = path_base / 'axes_enrichment' / 'annotations'\n",
    "path_spots = path_base / 'spot_detection'\n",
    "\n",
    "path_save = path_base / 'axes_enrichment' / 'results'\n",
    "if not path_save.is_dir():\n",
    "    path_save.mkdir(parents=True)\n",
    "\n",
    "# Loop over all spot detection results\n",
    "for f_spots in path_spots.glob('*__spots.csv'):\n",
    "\n",
    "    print(f'>>> Processing spot detection file {f_spots}')\n",
    "    name_spots = f_spots.name\n",
    "\n",
    "    # Annnotation file\n",
    "    name_json = name_spots.replace('__spots.csv','.json')\n",
    "    name_json_full = (path_json / name_json).resolve()\n",
    "\n",
    "    if not name_json_full.is_file():\n",
    "        print(f'Annotation does not exist: {name_json_full}')\n",
    "        continue\n",
    "\n",
    "    with open(name_json_full, encoding='utf-8-sig') as fh:\n",
    "        data_json = json.load(fh)\n",
    "\n",
    "        # Overwrite default file size if bounding box is present\n",
    "        if 'bbox' in data_json:\n",
    "            image_size = (int(data_json['bbox'][2]-data_json['bbox'][0]+1),\n",
    "                                int(data_json['bbox'][3]-data_json['bbox'][1]+1))\n",
    "        else:\n",
    "            print('Image size not provided in geojson file.')\n",
    "\n",
    "        # Loop over list and create simple dictionary & get size of annotations\n",
    "        n_features = len(data_json['features'])\n",
    "        if n_features != 1:\n",
    "            print(f'Annotation file CAN ONLY contain 1 annotation, not {n_features}.')\n",
    "            continue\n",
    "\n",
    "        annot_type = data_json['features'][0]['geometry']['type']\n",
    "        if annot_type not in ['LineString']:\n",
    "            print(f'Annotation type {annot_type} not supported .')\n",
    "            continue            \n",
    "\n",
    "        line = np.squeeze(np.asarray(data_json['features'][0]['geometry']['coordinates'])).astype('int')\n",
    "\n",
    "        # >>>>> Process annotation\n",
    "\n",
    "        # >> Loop over polygon coordinates and create closed line\n",
    "\n",
    "        rr_all =  np.empty([0], dtype=int)\n",
    "        cc_all = np.empty([0], dtype=int)\n",
    "        img_mask = np.zeros(image_size)\n",
    "\n",
    "        for i in range(line.shape[0]-1):\n",
    "            r0 = line[i][1]\n",
    "            c0 = line[i][0]\n",
    "            r1 = line[i+1][1]\n",
    "            c1 = line[i+1][0]\n",
    "\n",
    "            rr, cc = draw.line(r0, c0, r1, c1)\n",
    "            rr_all = np.append(rr_all,rr)\n",
    "            cc_all = np.append(cc_all,cc)\n",
    "\n",
    "        # >> Remove duplicate entries   \n",
    "        line_sampled = np.column_stack((cc_all,rr_all)) \n",
    "        _,idx = np.unique(line_sampled, axis=0, return_index=True)\n",
    "        line_sampled = line_sampled[np.sort(idx)]\n",
    "\n",
    "        img_mask[rr_all, cc_all] = 1\n",
    "        edt, inds = ndimage.distance_transform_edt(np.logical_not(img_mask), return_indices=True)\n",
    "\n",
    "        # >> Distance along the line\n",
    "        d = np.diff(line_sampled, axis=0)\n",
    "        segdists = np.sqrt((d ** 2).sum(axis=1))\n",
    "\n",
    "        dist_orig = np.cumsum(segdists)\n",
    "        dist_orig = np.append(0,dist_orig)\n",
    "\n",
    "        # >> Set 0 to turning point\n",
    "        ind0 = np.argmin(line_sampled[:,0])\n",
    "        dist_orig = dist_orig - dist_orig[ind0]\n",
    "\n",
    "        # >> Set min to upper right corner\n",
    "        y_start = line_sampled[0,1]\n",
    "        y_end = line_sampled[-1,1]\n",
    "        if y_end < y_start:\n",
    "            dist_orig = -1*dist_orig\n",
    "\n",
    "\n",
    "        # >>>>  Read spot detection file\n",
    "        spots = pd.read_csv(f_spots, sep=',').to_numpy()\n",
    "\n",
    "        #  >> Get index of closest pixel on the line \n",
    "        edt_spots = edt[spots[:,1], spots[:,2]]\n",
    "        ind_spots_keep = edt_spots <= dist_max\n",
    "\n",
    "        inds_spots_ax0 = inds[0,spots[:,1], spots[:,2]]\n",
    "        inds_spots_ax1 = inds[1,spots[:,1], spots[:,2]]\n",
    "        inds_spots = np.column_stack((inds_spots_ax1,inds_spots_ax0))\n",
    "\n",
    "        inds_spots = inds_spots[ind_spots_keep,:]\n",
    "\n",
    "        unique_rows, counters = np.unique(inds_spots, axis=0, return_counts=True)\n",
    "\n",
    "        # >>>>> Combine results in data-frame\n",
    "        df_line = pd.DataFrame(data=line_sampled,columns=[\"ax1\", \"ax2\"])\n",
    "        df_line['dist_orig'] = dist_orig\n",
    "        df_spots = pd.DataFrame(data=unique_rows,columns=[\"ax1\", \"ax2\"])\n",
    "        df_spots['n_rna'] = counters\n",
    "\n",
    "        # >> Merge the data frames & save\n",
    "        df_results = pd.merge(df_line, df_spots,  how='left', left_on=['ax1','ax2'], right_on = ['ax1','ax2'])\n",
    "        df_results[\"n_rna\"] = df_results[\"n_rna\"].fillna(0)\n",
    "        #df_results['n_rna_movavg'] = df_results[\"n_rna\"].rolling(window=n_avg).mean()\n",
    "\n",
    "        name_save = path_save / name_spots.replace('__spots.csv','__axes_enrich.csv')\n",
    "        df_results.to_csv(name_save, index=False)\n",
    "\n",
    "        # >>>> Binning of data\n",
    "        bins_neg = np.sort(-np.arange(bin_step, -dist_orig.min() , bin_step, dtype='int16'))\n",
    "        bins_pos = np.arange(0, dist_orig.max(), bin_step, dtype='int16')\n",
    "        dist_bin = np.concatenate((bins_neg, bins_pos), axis=0)\n",
    "\n",
    "        # Determine to which bin data-points belong\n",
    "        digitized = np.digitize(df_results['dist_orig'], dist_bin)\n",
    "\n",
    "        # Sum RNA counts for each bin\n",
    "        n_rna_bin = [df_results['n_rna'][digitized == i].sum() for i in range(1, len(dist_bin))]\n",
    "\n",
    "        df_bin = pd.DataFrame({'dist_bin': dist_bin[0:-1],\n",
    "                            'n_rna_bin': n_rna_bin})\n",
    "\n",
    "        name_save = path_save / name_spots.replace('__spots.csv','__axes_enrich__binned.csv')\n",
    "        df_bin.to_csv(name_save, index=False)\n",
    "\n",
    "        # >>>  Plot results\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2)\n",
    "        fig.set_size_inches((10, 10))\n",
    "\n",
    "        ax[0][0].imshow(edt,cmap=\"hot\")\n",
    "        ax[0][0].get_xaxis().set_visible(False)\n",
    "        ax[0][0].get_yaxis().set_visible(False)\n",
    "        ax[0][0].set_title('Axes and distance from axes')\n",
    "        ax[0][0].plot(line[:,0], line[:,1], color='b')\n",
    "\n",
    "        ax[0][1].plot(line[:,0], line[:,1], color='b')\n",
    "        ax[0][1].set_title('Spots (green-kept, red-removed)')\n",
    "        ax[0][1].scatter(spots[ind_spots_keep,2], spots[ind_spots_keep,1], color='g', s=1)\n",
    "        ax[0][1].scatter(spots[np.logical_not(ind_spots_keep),2], spots[np.logical_not(ind_spots_keep),1], color='r', s=1)\n",
    "        ax[0][1].invert_yaxis()\n",
    "        ax[0][1].set_aspect('equal', 'box')\n",
    "\n",
    "        ax[1][0].hist(edt_spots, 50, density=True, facecolor='g', alpha=0.75)\n",
    "        ax[1][0].set_title('Hist of distance from axis')\n",
    "        ax[1][0].set_ylabel('Frequency')\n",
    "        ax[1][0].set_xlabel('Distance [pix]')\n",
    "\n",
    "        sns.lineplot(x=\"dist_orig\", y=\"n_rna\", data=df_results,ax=ax[1][1])\n",
    "        sns.lineplot(x=\"dist_bin\", y=\"n_rna_bin\", data=df_bin)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        name_save = path_save / name_spots.replace('__spots.csv','__axes_enrich.png')\n",
    "        plt.savefig(name_save,dpi=300)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fq-imjoy)",
   "language": "python",
   "name": "fq-imjoy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}