<docs lang="markdown">
[TODO: write documentation for this plugin.]
</docs>

<config lang="json">
{
  "name": "CALC-axes-enrich-INT",
  "type": "native-python",
  "version": "0.0.1",
  "description": "Calculate intensity levels along annotated axes.",
  "tags": "",
  "ui": [
        "<span style='font-weight: 550; color:#666362'>Path DATA</span>: {id: 'path_base', type: 'string', placeholder: 'paste-path-to-data'}",
        "<span style='font-weight: 550; color:#666362'>CH annotation</span>: {id: 'ch_annotation', type: 'string', placeholder: 'w2CY5'}",
        "<span style='font-weight: 550; color:#666362'>CH image</span>: {id: 'ch_img', type: 'string', placeholder: 'w3cy3'}",
        "<span style='font-weight: 550; color:#666362'>MAX distance</span>: {id: 'dist_max', type: 'number', placeholder: 100}",
        "<span style='font-weight: 550; color:#666362'>N bin</span>: {id: 'bin_step', type: 'number', placeholder: 20}",
        "<span style='font-weight: 550; color:#666362'>Int quantile</span>: {id: 'quantile_intensity', type: 'number', placeholder: 80}"
        ],
  "cover": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "api_version": "0.1.7",
  "env": "",
  "permissions": [],
  "requirements": ["pip: matplotlib scikit-image numpy pandas seaborn"],
  "dependencies": []
}
</config>

<script lang="python">
from imjoy import api

import asyncio
import sys

import json
from pathlib import Path
import numpy as np
from scipy import ndimage
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from skimage import draw
from skimage.io import imread


if sys.platform == "darwin":
    import matplotlib
    matplotlib.use('PS')

class ImJoyPlugin():
    def setup(self):
        api.log('RNA-Axes-Enrichment plugin initialized')

    async def run(self, ctx):

        # >>> CHECK INPUT PARAMETERS
        api.log(ctx.config)

        path_base_str = ctx.config.path_base
        ch_annotation = ctx.config.ch_annotation
        ch_img = ctx.config.ch_img
        quantile_intensity = ctx.config.quantile_intensity
        dist_max = ctx.config.dist_max
        bin_step = ctx.config.bin_step


        # Path containing data, and to save results
        if path_base_str == 'paste-path-to-data':
            api.alert('Path containing data to be processed has to be specified.')
            return

        path_base = Path(path_base_str)

        # >>> PROCESS FOLDERS

        # Different folders
        path_annotations = path_base / 'analysis' / 'axes_enrichment' / 'annotations'
        if not path_annotations.is_dir():
            api.log('Folder with annotations does not exist: {path_annotations}')
            
        path_images = path_base / 'acquisition'

        path_save = path_base / 'analysis' / 'axes_enrichment' / f'results__intensity_q{round(quantile_intensity)}'
        if not path_save.is_dir():
            path_save.mkdir(parents=True)

        # Loop over all spot detection results
        for f_annotation in path_annotations.glob('*.json'):

            api.showStatus(f'>>> Processing annotation {f_annotation}')
            name_json = f_annotation.name
            
            # >>> Load image
            name_img = name_json.replace('.json','.tif').replace(ch_annotation,ch_img)
            f_img = path_images / name_img
            
            if not f_img.is_file():
                api.log(f'Image does not exist: {f_img}')
                continue
            
            img_3d = imread(str(f_img))
            img_2d = img_3d.max(axis=0)
            image_size = img_2d.shape
            
            # >>> Process annnotation file    
            with open(f_annotation, encoding='utf-8-sig') as fh:
                
                data_json = json.load(fh)
                
                # Loop over list and create simple dictionary & get size of annotations
                n_features = len(data_json['features'])
                if n_features != 1:
                    api.log(f'Annotation file CAN ONLY contain 1 annotation, not {n_features}.')
                    continue

                annot_type = data_json['features'][0]['geometry']['type']
                if annot_type not in ['LineString']:
                    api.log(f'Annotation type {annot_type} not supported .')
                    continue            

                line = np.squeeze(np.asarray(data_json['features'][0]['geometry']['coordinates'])).astype('int')

                # Flip orientation of y axis
                line[:,1] = image_size[1] -  line[:,1] - 1

                # >>>>> Process annotation

                # >> Loop over polygon coordinates and create closed line
                rr_all =  np.empty([0], dtype=int)
                cc_all = np.empty([0], dtype=int)
                img_mask = np.zeros(image_size)

                for i in range(line.shape[0]-1):
                    r0 = line[i][1]
                    c0 = line[i][0]
                    r1 = line[i+1][1]
                    c1 = line[i+1][0]

                    rr, cc = draw.line(r0, c0, r1, c1)
                    rr_all = np.append(rr_all,rr)
                    cc_all = np.append(cc_all,cc)

                # >> Remove duplicate entries   
                line_sampled = np.column_stack((cc_all,rr_all)) 
                _,idx = np.unique(line_sampled, axis=0, return_index=True)
                line_sampled = line_sampled[np.sort(idx)]

                img_mask[rr_all, cc_all] = 1
                edt, inds = ndimage.distance_transform_edt(np.logical_not(img_mask), return_indices=True)

                # >> Distance along the line
                d = np.diff(line_sampled, axis=0)
                segdists = np.sqrt((d ** 2).sum(axis=1))

                dist_orig = np.cumsum(segdists)
                dist_orig = np.append(0,dist_orig)

                # >> Set 0 to turning point
                ind0 = np.argmin(line_sampled[:,0])
                dist_orig = dist_orig - dist_orig[ind0]

                # >> Set min to upper right corner
                y_start = line_sampled[0,1]
                y_end = line_sampled[-1,1]
                if y_end < y_start:
                    dist_orig = -1*dist_orig
          
                # >>> Intensities and index in annotation
                int_in_annotation = img_2d[edt<dist_max]
                inds_ax0_in_annotation = inds[0,edt<dist_max]
                inds_ax1_in_annotation = inds[1,edt<dist_max]
                inds_in_annotation = np.column_stack((inds_ax1_in_annotation,inds_ax0_in_annotation))
                
                unique_rows, unique_inverse = np.unique(inds_in_annotation, axis=0, return_inverse=True)

                # >>>> Intensity along line
                int_line = np.zeros((unique_rows.shape[0]))
                for index, unique_row in enumerate(unique_rows):     
                    inds_match = np.where(np.all(inds_in_annotation==unique_row,axis=1))[0]
                    int_line[index] = np.quantile(int_in_annotation[inds_match], quantile_intensity/100)
                
                # >>>>> Combine results in data-frame
                df_line = pd.DataFrame(data=line_sampled,columns=["ax1", "ax2"])
                df_line['dist_orig'] = dist_orig
                df_intensity = pd.DataFrame(data=unique_rows,columns=["ax1", "ax2"])
                df_intensity['int'] = int_line   
                    
                # >> Merge the data frames & save
                df_results = pd.merge(df_line, df_intensity,  how='left', left_on=['ax1','ax2'], right_on = ['ax1','ax2'])
                df_results["int"] = df_results["int"].fillna(0)    
                    
                name_save = path_save / name_json.replace('.json','__axes_enrich_int.csv')
                df_results.to_csv(name_save, index=False)

                # >>>> Binning of data
                bins_neg = np.sort(-np.arange(bin_step, -dist_orig.min() , bin_step, dtype='int16'))
                bins_pos = np.arange(0, dist_orig.max(), bin_step, dtype='int16')
                dist_bin = np.concatenate((bins_neg, bins_pos), axis=0)

                # Determine to which bin data-points belong
                digitized = np.digitize(df_results['dist_orig'], dist_bin)

                # Sum RNA counts for each bin
                int_bin = [df_results['int'][digitized == i].median() for i in range(1, len(dist_bin))]

                df_bin = pd.DataFrame({'dist_bin': dist_bin[0:-1],
                                      'int_bin': int_bin})

                name_save = path_save / name_json.replace('.json','__axes_enrich_int__binned.csv')
                df_bin.to_csv(name_save, index=False)            
                
                # >>>  Plot results

                fig, ax = plt.subplots(2, 2)
                fig.set_size_inches((10, 10))

                ax[0][0].imshow(edt,cmap="hot")
                ax[0][0].get_xaxis().set_visible(False)
                ax[0][0].get_yaxis().set_visible(False)
                ax[0][0].set_title('Axes and distance from axes')
                ax[0][0].plot(line[:,0], line[:,1], color='b')
                
                ax[0][1].imshow(img_2d,cmap="hot")
                ax[0][1].get_xaxis().set_visible(False)
                ax[0][1].get_yaxis().set_visible(False)
                ax[0][1].set_title('Axes and distance from axes')
                ax[0][1].plot(line[:,0], line[:,1], color='b')


                sns.lineplot(x="dist_orig", y="int", data=df_results,ax=ax[1][0])
                sns.lineplot(x="dist_bin", y="int_bin", data=df_bin,ax=ax[1][1])

                plt.tight_layout()

                name_save = path_save / name_json.replace('.json','__axes_enrich_int.png')
                plt.savefig(name_save,dpi=300)
                plt.close()

api.export(ImJoyPlugin())
</script>